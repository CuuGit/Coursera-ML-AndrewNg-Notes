第9周
=====
[TOC]
十五、异常检测(Anomaly Detection)
---------------------------------

### 15.1 问题的动机

参考文档: 15 - 1 - Problem Motivation (8 min).mkv

在接下来的一系列视频中，我将向大家介绍异常检测(**Anomaly detection**)问题。这是机器学习算法的一个常见应用。这种算法的一个有趣之处在于：它虽然主要用于非监督学习问题，但从某些角度看，它又类似于一些监督学习问题。

什么是异常检测呢？为了解释这个概念，让我举一个例子吧：

假想你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时，你需要进行**QA**(质量控制测试)，而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，比如引擎运转时产生的热量，或者引擎的振动等等。

![](../images/93d6dfe7e5cb8a46923c178171889747.png)

这样一来，你就有了一个数据集，从$x^{(1)}$到$x^{(m)}$，如果你生产了$m$个引擎的话，你将这些数据绘制成图表，看起来就是这个样子：

![](../images/fe4472adbf6ddd9d9b51d698cc750b68.png)

这里的每个点、每个叉，都是你的无标签数据。这样，异常检测问题可以定义如下：我们假设后来有一天，你有一个新的飞机引擎从生产线上流出，而你的新飞机引擎有特征变量$x_{test}$。所谓的异常检测问题就是：我们希望知道这个新的飞机引擎是否有某种异常，或者说，我们希望判断这个引擎是否需要进一步测试。因为，如果它看起来像一个正常的引擎，那么我们可以直接将它运送到客户那里，而不需要进一步的测试。

给定数据集 $x^{(1)},x^{(2)},..,x^{(m)}$，我们假使数据集是正常的，我们希望知道新的数据 $x_{test}$ 是不是异常的，即这个测试数据不属于该组数据的几率如何。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性 $p(x)$。

![](../images/65afdea865d50cba12d4f7674d599de5.png)

上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。

这种方法称为密度估计，表达如下：

$$
if \quad p(x)
\begin{cases}
< \varepsilon & anomaly \\
> =\varepsilon & normal
\end{cases}
$$

欺诈检测：

$x^{(i)} = {用户的第i个活动特征}$

模型$p(x)$ 为我们其属于一组数据的可能性，通过$p(x) < \varepsilon$检测非正常用户。

异常检测主要用来识别欺骗。例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。

再一个例子是检测一个数据中心，特征可能包含：内存使用情况，被访问的磁盘数量，**CPU**的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错了。

### 15.2 高斯分布

参考视频: 15 - 2 - Gaussian Distribution (10 min).mkv

在这个视频中，我将介绍高斯分布，也称为正态分布。回顾高斯分布的基本知识。

通常如果我们认为变量 $x$ 符合高斯分布 $x \sim N(\mu, \sigma^2)$则其概率密度函数为：
$p(x,\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$
我们可以利用已有的数据来预测总体中的$μ$和$σ^2$的计算方法如下：
$\mu=\frac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}$


$\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2$

高斯分布样例：

![](../images/fcb35433507a56631dde2b4e543743ee.png)

注：机器学习中对于方差我们通常只除以$m$而非统计学中的$(m-1)$。这里顺便提一下，在实际使用中，到底是选择使用$1/m$还是$1/(m-1)$其实区别很小，只要你有一个还算大的训练集，在机器学习领域大部分人更习惯使用$1/m$这个版本的公式。这两个版本的公式在理论特性和数学特性上稍有不同，但是在实际使用中，他们的区别甚小，几乎可以忽略不计。

### 15.3 算法 

参考视频: 15 - 3 - Algorithm (12 min).mkv

在本节视频中，我将应用高斯分布开发异常检测算法。

异常检测算法：

对于给定的数据集 $x^{(1)},x^{(2)},...,x^{(m)}$，我们要针对每一个特征计算 $\mu$ 和 $\sigma^2$ 的估计值。

$\mu_j=\frac{1}{m}\sum\limits_{i=1}^{m}x_j^{(i)}$

$\sigma_j^2=\frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2$

一旦我们获得了平均值和方差的估计值，给定新的一个训练实例，根据模型计算 $p(x)$：

$p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod\limits_{j=1}^1\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$

当$p(x) < \varepsilon$时，为异常。

下图是一个由两个特征的训练集，以及特征的分布情况：

![](../images/ba47767a11ba39a23898b9f1a5a57cc5.png)

下面的三维图表表示的是密度估计函数，$z$轴为根据两个特征的值所估计$p(x)$值：

![](../images/82b90f56570c05966da116c3afe6fc91.jpg)

我们选择一个$\varepsilon$，将$p(x) = \varepsilon$作为我们的判定边界，当$p(x) > \varepsilon$时预测数据为正常数据，否则为异常。

在这段视频中，我们介绍了如何拟合$p(x)$，也就是 $x$的概率值，以开发出一种异常检测算法。同时，在这节课中，我们也给出了通过给出的数据集拟合参数，进行参数估计，得到参数 $\mu$ 和 $\sigma$，然后检测新的样本，确定新样本是否是异常。

在接下来的课程中，我们将深入研究这一算法，同时更深入地介绍，怎样让算法工作地更加有效。

总结异常检测算法步骤：

1. 选择你认为可能有用的特征 $x_{i}$ ，如{$x_1, x_2, ..., x_n$}

2. 计算参数：$\mu_{1}, \mu_{2}, ... , \mu_{n}$ ， $\sigma_{1}^{2}, \sigma_{2}^{2}, ... ,\sigma_{n}^{2}$

   ​	$\mu_j = \frac{1}{m}\sum_\limits{i=1}^{m}{x_j^{(i)}}$

   ​	$\sigma_j^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x_j^{(i)}-\mu_j)^2$

3. 给定新样本$x$ ，根据模型计算$p(x)$：

   ​	$p(x)=\prod\limits_{j=1}^{n}p(x_i, \mu_i, \sigma_j^2)=\prod\limits_{j=1}^{n}\frac{1}{\sqrt{2\pi}\sigma_{j}}exp(-\frac{(x_i-\mu_i)^2}{2\sigma_j^2})$

   若$p(x)<\varepsilon$，则为异常。$\varepsilon$ 为阈值。

### 15.4 开发和评价一个异常检测系统

参考视频: 15 - 4 - Developing and Evaluating an Anomaly Detection System (13 min). mkv

异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量 $ y$ 的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。

例如：我们有10000台正常引擎的数据，有20台异常引擎的数据。 我们这样分配数据：

​			6000台正常引擎的数据作为训练集。（用来计算$\mu_j, \sigma_j^2$）

​			2000台正常引擎和10台异常引擎的数据作为交叉检验集

​			2000台正常引擎和10台异常引擎的数据作为测试集

具体的评价方法如下：

1. 根据测试集数据，我们估计特征的平均值和方差并构建$p(x)$函数

2. 对交叉检验集，我们尝试使用不同的$\varepsilon$值作为阀值，并预测数据是否异常，根据$F1$值或者查准率与查全率的比例来选择 $\varepsilon$

3. 选出 $\varepsilon$ 后，针对测试集进行预测，计算异常检验系统的$F1$值，或者查准率与查全率之比

### 15.5 异常检测与监督学习对比

参考视频: 15 - 5 - Anomaly Detection vs. Supervised Learning (8 min).mkv

之前我们构建的异常检测系统也使用了带标记的数据，与监督学习有些相似，下面的对比有助于选择采用监督学习还是异常检测：

两者比较：

| 异常检测                                | 监督学习                                     |
| ----------------------------------- | ---------------------------------------- |
| 非常少量的正向类（异常数据 $y=1$）, 大量的负向类（$y=0$） | 同时有大量的正向类和负向类                            |
| 许多不同种类的异常，非常难。根据非常 少量的正向类数据来训练算法。   | 有足够多的正向类实例，足够用于训练 算法，未来遇到的正向类实例可能与训练集中的非常近似。 |
| 未来遇到的异常可能与已掌握的异常、非常的不同。             |                                          |
| 例如： 欺诈行为检测 生产（例如飞机引擎）检测数据中心的计算机运行状况 | 例如：邮件过滤器 天气预报 肿瘤分类                       |

希望这节课能让你明白一个学习问题的什么样的特征，能让你把这个问题当做是一个异常检测，或者是一个监督学习的问题。另外，对于很多技术公司可能会遇到的一些问题，通常来说，正样本的数量很少，甚至有时候是0，也就是说，出现了太多没见过的不同的异常类型，那么对于这些问题，通常应该使用的算法就是异常检测算法。

**==我们是基于高斯分布构建异常检测系统的，高斯分布也就意味着我们的数据分布不均匀，正样本较多或负样本较多。但即使我们的正样本和负样本比较均匀，不是高斯分布，异常检测系统往往也能正常运行。==**

### 15.6 选择特征

参考视频: 15 - 6 - Choosing What Features to Use (12 min).mkv

对于异常检测算法，我们使用的特征是至关重要的，下面谈谈如何选择特征：

异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布，例如使用对数函数：$x= log(x+c)$，其中 $c$ 为非负常数； 或者 $x=x^c$，$c$为 0-1 之间的一个分数，等方法。(编者注：在**python**中，通常用`np.log1p()`函数，$log1p$就是 $log(x+1)$，可以避免出现负数结果，反向函数就是`np.expm1()`)

![](../images/0990d6b7a5ab3c0036f42083fe2718c6.jpg)

==我们可以对不符合高斯分布的特征进行转换，例如：特征$x_1$变成$log(x_1)$，特征$x_2$变成$log(x_2+1)$，特征$x_3$变成$x^{\frac{1}{2}}$等等，所有的这些log、常数c、指数$\frac{1}{2}$都是可以调整的，目的是为了让特征符合高斯分布。==

误差分析：

一个常见的问题是一些异常的数据可能也会有较高的$p(x)$值，因而被算法认为是正常的。这种情况下误差分析能够帮助我们，我们可以分析那些被算法错误预测为正常的数据，观察能否找出一些问题。我们可能能从问题中发现我们需要增加一些新的特征，增加这些新特征后获得的新算法能够帮助我们更好地进行异常检测。

异常检测误差分析：

![](../images/f406bc738e5e032be79e52b6facfa48e.png)

我们通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小），例如，在检测数据中心的计算机状况的例子中，我们可以用**CPU**负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中。

在这段视频中，我们介绍了如何选择特征，以及对特征进行一些小小的转换，让数据更像正态分布，然后再把数据输入异常检测算法。同时也介绍了建立特征时，进行的误差分析方法，来捕捉各种异常的可能。希望你通过这些方法，能够了解如何选择好的特征变量，从而帮助你的异常检测算法，捕捉到各种不同的异常情况。

### 15.7 多元高斯分布（选修）

参考视频: 15 - 7 - Multivariate Gaussian Distribution (Optional) (14 min).mkv

假使我们有两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。

下图中是两个相关特征，洋红色的线（根据ε的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的**X**所代表的数据点很可能是异常值，但是其$p(x)$值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判定边界。

![](../images/598db991a7c930c9021cec5f6ab9beb9.png)

在一般的高斯分布模型中，我们计算 $p(x)$ 的方法是：通过分别计算每个特征对应的几率然后将其累乘起来。

在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起来计算 $p(x)$。

我们首先计算所有特征的平均值，然后再计算协方差矩阵：
$p(x)=\prod_\limits{j=1}^np(x_j;\mu,\sigma_j^2)=\prod_\limits{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$

$\mu=\frac{1}{m}\sum_\limits{i=1}^mx^{(i)}$

$\Sigma = \frac{1}{m}\sum_\limits{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)$

注:其中$\mu $ 是一个向量，其每一个单元都是原特征矩阵中一行数据的均值。最后我们计算多元高斯分布的$p\left( x \right)$:
$p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)$
其中：

$|\Sigma|$是定矩阵（行列式），在 **Octave** 中用 `det(sigma)`计算

$\Sigma^{-1}$ 是逆矩阵，下面我们来看看协方差矩阵是如何影响模型的：

![](../images/29df906704d254f18e92a63173dd51e7.jpg)

上图是5个不同的模型，从左往右依次分析：

1. 是一个一般的高斯分布模型

2. 通过协方差矩阵，令特征1拥有较小的偏差，同时保持特征2的偏差

3. 通过协方差矩阵，令特征2拥有较大的偏差，同时保持特征1的偏差

4. 通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的正相关性

5. 通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的负相关性

多元高斯分布模型与原高斯分布模型的关系：

可以证明的是，原本的高斯分布模型是多元高斯分布模型的一个子集，即像上图中的第1、2、3，3个例子所示，如果协方差矩阵只在对角线的单位上有非零的值时，即为原本的高斯分布模型了。

==原高斯分布模型和多元高斯分布模型的比较==：

| 原高斯分布模型                                               | 多元高斯分布模型                                             |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 不能捕捉特征之间的相关性 但可以通过将特征进行组合的方法来解决 | 自动捕捉特征之间的相关性                                     |
| 计算代价低，能适应大规模的特征                               | 计算代价较高 训练集较小时也同样适用                          |
|                                                              | 必须要有 $m>n$，不然的话协方差矩阵$\Sigma$不可逆的，通常需要 $m>10n​$ 另外特征冗余也会导致协方差矩阵不可逆 |

==在实际应用中，当你发现 $\Sigma$ 是不可逆的，即奇异矩阵，通常是因为不满足 $m>n$ 或者存在冗余的特征。冗余的特征意味着如$x_2=x_1$或者$x_3=x_4+x_5$这样的重复特征或无意义特征。站在线性代数的角度，冗余特征即代表着线性相关。==

原高斯分布模型被广泛使用着，如果特征之间在某种程度上存在相互关联的情况，我们可以通过构造新新特征的方法来捕捉这些相关性。

如果训练集不是太大，并且没有太多的特征，我们可以使用多元高斯分布模型。

### 15.8 使用多元高斯分布进行异常检测（可选）

参考视频: 15 - 8 - Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min).mkv

在我们谈到的最后一个视频，关于多元高斯分布，看到的一些建立的各种分布模型，当你改变参数，$\mu$ 和 $\Sigma$。在这段视频中，让我们用这些想法，并应用它们制定一个不同的异常检测算法。

要回顾一下多元高斯分布和多元正态分布：

![](../images/3dbee365617e9264831400e4de247adc.png)

分布有两个参数， $\mu$ 和 $\Sigma$。其中$\mu$这一个$n$维向量和 $\Sigma$ 的协方差矩阵，是一种$n\times n$的矩阵。而这里的公式$x$的概率，如按 $\mu$ 和参数化 $\Sigma$，和你的变量 $\mu$ 和 $\Sigma$，你可以得到一个范围的不同分布一样，你知道的，这些都是三个样本，那些我们在以前的视频看过了。

因此，让我们谈谈参数拟合或参数估计问题：

我有一组样本${{{ x^{(1)},x^{(2)},...,x^{(m)}} }}$是一个$n$维向量，我想我的样本来自一个多元高斯分布。我如何尝试估计我的参数 $\mu$ 和 $\Sigma$ 以及标准公式？

估计他们是你设置 $\mu$ 是你的训练样本的平均值。

$\mu=\frac{1}{m}\sum_{i=1}^{m}x^{(i)}$
并设置$\Sigma$：
$\Sigma=\frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu)(x^{(i)}-\mu)^T$
这其实只是当我们使用**PCA**算法时候，有 $\Sigma$ 时写出来。所以你只需插入上述两个公式，这会给你你估计的参数 $\mu$ 和你估计的参数 $\Sigma$。所以，这里给出的数据集是你如何估计 $\mu$ 和 $\Sigma$。让我们以这种方法而只需将其插入到异常检测算法。那么，我们如何把所有这一切共同开发一个异常检测算法？

![](../images/d1a228f2bec262f2206379ed844c7f4a.png)

首先，我们把我们的训练集，和我们的拟合模型，我们计算$p(x)$，要知道，设定$\mu$和描述的一样$\Sigma$。

![](../images/015cee3a224dde6da0181215cf91a23d.png)

如图，该分布在中央最多，越到外面的圈的范围越小。

并在该点是出路这里的概率非常低。

原始模型与多元高斯模型的关系如图：

==普通的高斯分布通过增加相关特征（如两个原特征的比值）的方式也可以有椭圆形的等高线，达到类似多元高斯分布的效果，但其椭圆形永远是轴对称的，也就是椭圆不可能倾斜，要么水平要么竖直。相当于多元高斯分布的协方差矩阵非对角线上的元素的数值相等，即椭圆横向或竖向拉长或缩短的比例一致。==

==多元高斯分布的对角线上数值全为$\sigma^2$，即$\sigma_1^2,\sigma^2_2...\sigma^n_2$，非对角线上的元素全为0时，则会与普通的高斯分布一模一样。==

其中：协方差矩阵$\Sigma$为：

![](../images/7104dd2548f1251e4c423e059d1d2594.png)

原始模型和多元高斯分布比较如图：

![](../images/f4585239738f2b5149608879fa166889.png)

十六、推荐系统(Recommender Systems)
-----------------------------------

### 16.1 问题形式化

参考视频: 16 - 1 - Problem Formulation (8 min).mkv

在接下来的视频中，我想讲一下推荐系统。我想讲推荐系统有两个原因：

第一、仅仅因为它是机器学习中的一个重要的应用。在过去几年，我偶尔访问硅谷不同的技术公司，我常和工作在这儿致力于机器学习应用的人们聊天，我常问他们，最重要的机器学习的应用是什么，或者，你最想改进的机器学习应用有哪些。我最常听到的答案是推荐系统。现在，在硅谷有很多团体试图建立很好的推荐系统。因此，如果你考虑网站像亚马逊，或网飞公司或易趣，或**iTunes Genius**，有很多的网站或系统试图推荐新产品给用户。如，亚马逊推荐新书给你，网飞公司试图推荐新电影给你，等等。这些推荐系统，根据浏览你过去买过什么书，或过去评价过什么电影来判断。这些系统会带来很大一部分收入，比如为亚马逊和像网飞这样的公司。因此，对推荐系统性能的改善，将对这些企业的有实质性和直接的影响。

推荐系统是个有趣的问题，在学术机器学习中因此，我们可以去参加一个学术机器学习会议，推荐系统问题实际上受到很少的关注，或者，至少在学术界它占了很小的份额。但是，如果你看正在发生的事情，许多有能力构建这些系统的科技企业，他们似乎在很多企业中占据很高的优先级。这是我为什么在这节课讨论它的原因之一。

我想讨论推荐系统地第二个原因是：这个班视频的最后几集我想讨论机器学习中的一些大思想，并和大家分享。这节课我们也看到了，对机器学习来说，特征是很重要的，你所选择的特征，将对你学习算法的性能有很大的影响。因此，在机器学习中有一种==大思想==，它针对一些问题，可能并不是所有的问题，而是一些问题，有算法可以为你自动学习一套好的特征。因此，不要试图手动设计，而手写代码这是目前为止我们常干的。有一些设置，你可以有一个算法，仅仅学习其使用的特征，推荐系统就是类型设置的一个例子。还有很多其它的，但是通过推荐系统，我们将领略一小部分特征学习的思想，至少，你将能够了解到这方面的一个例子，我认为，机器学习中的大思想也是这样。因此，让我们开始讨论推荐系统问题形式化。

我们从一个例子开始定义推荐系统的问题。

假使我们是一个电影供应商，我们有 5 部电影和 4 个用户，我们要求用户为电影打分。分数为星级，即0星到5星之间。

![](../images/c2822f2c28b343d7e6ade5bd40f3a1fc.png)

前三部电影是爱情片，后两部则是动作片，我们可以看出**Alice**和**Bob**似乎更倾向与爱情片， 而 **Carol** 和 **Dave** 似乎更倾向与动作片。并且没有一个用户给所有的电影都打过分。我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据。

下面引入一些标记：

$n_u$ 代表用户的数量，下标 $u$ 表示具体那个用户

$n_m$ 代表电影的数量

$r(i, j)$ 如果用户j给电影 $i$ 评过分则 $r(i,j)=1$

$y^{(i, j)}$ 代表用户 $j$ 给电影$i$的评分

$m_j$代表用户 $j$ 评过分的电影的总数

### 16.2 基于内容的推荐系统

参考视频: 16 - 2 - Content Based Recommendations (15 min).mkv

在一个基于内容的推荐系统算法中，我们假设对于我们希望推荐的东西有一些数据，这些数据是有关这些东西的特征。

在我们的例子中，我们可以假设每部电影都有两个特征，如$x_1$代表电影的浪漫程度，$x_2$ 代表电影的动作程度。例如第一部电影的爱情成为0.9，动作程度为0，第二部电影的爱情程度为1，动作程度为0.01。

![](../images/747c1fd6bff694c6034da1911aa3314b.png)

则每部电影都有一个特征向量，如$x^{(1)}$是第一部电影的特征向量为$\begin{bmatrix}1\\0.9\\0\end{bmatrix}$，$x^{(2)}$是第二部电影的特征向量为$\begin{bmatrix}1\\1\\0.01\end{bmatrix}$。加入一列特征$x_0^{(i)}=1$，原始特征数依然是$n=2$。

下面我们要基于这些特征来构建一个推荐系统算法。
假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如${{\theta }^{(1)}}$是第一个用户的模型的参数。
于是，我们有：

​		$\theta^{(j)}$用户 $j$ 的参数向量，$\theta^{(j)}\in{\R^{n+1}}$

​		$x^{(i)}$电影 $i$ 的特征向量

对于用户 $j$ 和电影 $i$，我们预测评分为：==$(\theta^{(j)})^T x^{(i)}$==：

​		假如我们要预测Alice对于电影Cute puppies of love的评分，$x^{(3)}=\begin{bmatrix}1\\0.99\\0\end{bmatrix}$，假设$\theta^{1}=\begin{bmatrix}0\\5\\0\end{bmatrix}$，之后我们会将如何得到$\theta^{(j)}$，则 $j$ 对 $i$ 的评分为 $(\theta^{(1)})^Tx^{(3)}=4.95$。

代价函数：

​		$r^{(i,j)}=1$ if user j has rated movie i else 0

​		$y^{(i,j)}=$ rating by user j on movie i (if defined)

​		$\theta^{(j)}=$ parameter vector for user j

​		$x^{(i)}=$ feature vector for movie i

​		$m^{(j)}=$no. of movies  rated by user j

​		**To learn $\theta^{(j)}$:**

​		针对用户 $j$，该线性回归模型的代价为预测误差的平方和，加上正则化项：
$$
J(\theta^{(j)})=\min_{\theta (j)}\frac{1}{2}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\left(\theta_{k}^{(j)}\right)^2
$$

​		其中 $i:r(i,j)$表示我们只计算那些用户 $j$ 评过分的电影求和。在一般的线性回归模型中，误差项和正则项应该都是乘以$1/2m$，在这里我们将$m$去掉。并且我们不对方差项 $\theta_0$ 进行正则化处理。

​		**To learn $\theta^{(1)},\theta^{(2)},...,\theta^{(n_u)}$:**

​		上面的代价函数只是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和：
$$
J(\theta^{(1)},\theta^{(2)},...,\theta^{(n_u)})=\min_{\theta^{(1)},...,\theta^{(n_u)}} \frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2
$$
​		如果我们要用梯度下降法来求解最优解，我们计算代价函数的偏导数后得到梯度下降的更新公式为：

$$
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)} \quad (\text{for} \, k = 0)
$$

$$
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)}+\lambda\theta_k^{(j)}\right) \quad (\text{for} \, k\neq 0)
$$

​		其中的导数：
$$
\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)}+\lambda\theta_k^{(j)}\right)=\frac{\partial}{\partial{\theta^{(j)}_k}}J(\theta^{(1)},\theta^{(2)},...,\theta^{(n_u)})
$$


### 16.3 协同过滤

参考视频: 16 - 3 - Collaborative Filtering (10 min).mkv

在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征==训练出了每一个用户的参数==。

**Given $x^{(1)}, x^{(2)}, ... ,x^{(n_m)}$，estimate $\theta^{(1)},\theta^{(2)},...,\theta^{(n_u)}$:**
$$
\min_{\theta^{(1)},...,\theta^{(n_u)}} \frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2
$$
相反地，如果我们拥有用户的参数，我们可以学习得出==电影的特征==。

**Given $\theta^{(1)},\theta^{(2)},...,\theta^{(n_u)}$，estimate $x^{(1)}, x^{(2)}, ... ,x^{(n_m)}$:**
$$
\mathop{min}\limits_{x^{(1)},...,x^{(n_m)}}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:{r(i,j)=1}}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2
$$
然后不断重复过程：==${x}\longrightarrow{\theta}\longrightarrow{x}\longrightarrow{\theta}...$，最终求得最优的 $x$ 与 $\theta$ 。==

但是如果我们既没有用户的参数，也没有电影的特征，这两种方法都不可行了。==下节视频我们使用协同过滤算法可以同时学习这两者==。



### 16.4 协同过滤算法

参考视频: 16 - 4 - Collaborative Filtering Algorithm (9 min).mkv

前面的协同过滤优化目标：

给定$x^{(1)},...,x^{(n_m)}$，估计$\theta^{(1)},...,\theta^{(n_u)}$：==${x}\longrightarrow{\theta}$==
$$
\min_{\theta^{(1)},...,\theta^{(n_u)}}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2
$$

给定$\theta^{(1)},...,\theta^{(n_u)}$，估计$x^{(1)},...,x^{(n_m)}$：==${\theta}\longrightarrow{x}$==
$$
\min_{x^{(1)},...,x^{(n_m)}}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2
$$
==通过不断重复上述两个过程，${x}\rightarrow{\theta}\rightarrow{x}\rightarrow{\theta}...$ ，最终求解 $x$ 与 $\theta$ ，我们优化上述算法，将两个目标结合，同时求出最优 $x$ 与 $\theta$ ，不需要不断的迭代重复。==

同时最小化$x^{(1)},...,x^{(n_m)}$和$\theta^{(1)},...,\theta^{(n_u)}$：
$$
J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2
$$

$$
\min_{x^{(1)},...,x^{(n_m)} \\\ \theta^{(1)},...,\theta^{(n_u)}}J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)})
$$

使用梯度下降或者其他优化算法最小化上述代价函数，若梯度下降法，则求导得到的更新式如下：
$$
x_k^{(i)}:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}(((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\theta_k^{j}+\lambda x_k^{(i)}\right)
$$

$$
\theta_k^{(i)}:=\theta_k^{(i)}-\alpha\left(\sum_{i:r(i,j)=1}(((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda \theta_k^{(j)}\right)
$$

总结协同过滤算法使用步骤如下：

1. 初始 $x^{(1)},x^{(1)},...x^{(nm)},\ \theta^{(1)},\theta^{(2)},...,\theta^{(n_u)}$为一些随机小值，有点像神经网络那样选择很小的值。
2. 使用梯度下降算法最小化代价函数
3. 在训练完算法后，我们预测$(\theta^{(j)})^Tx^{(i)}$为用户 $j$ 给电影 $i$ 的评分

注意：

​			我们抛弃 $x_0=1$ ，即 $x^{(i)}\in{\R^{n}}$，因此 $\theta_0$ 也可以去掉了，即 $\theta^{(j)}\in{\R^{n}}$。原因是：我们在学习所有的特征和系数，即所有的特征即系数都是我们学习来的，所以我们没必要再强加一个特征为1，如果真的需要一个特征为1的话，算法会自己去学习得到，比如将 $x_3$ 学习为1。

### 16.5 向量化：低秩矩阵分解

参考视频: 16 - 5 - Vectorization\_ Low Rank Matrix Factorization (8 min).mkv

在上几节视频中，我们谈到了协同过滤算法，本节视频中我将会讲到有关该算法的向量化实现，以及说说有关该算法你可以做的其他事情。

举例子：

1. 当给出一件产品时，你能否找到与之相关的其它产品。

2. 一位用户最近看上一件产品，有没有其它相关的产品，你可以推荐给他。

我将要做的是：实现一种选择的方法，写出协同过滤算法的预测情况。

我们有关于五部电影的数据集，我将要做的是，将这些用户的电影评分，进行分组并存到一个矩阵中。

我们有五部电影，以及四位用户，那么 这个矩阵 $Y$ 就是一个5行4列的矩阵，它将这些电影的用户评分数据都存在矩阵里：

| **Movie**            | **Alice (1)** | **Bob (2)** | **Carol (3)** | **Dave (4)** |
| -------------------- | ------------- | ----------- | ------------- | ------------ |
| Love at last         | 5             | 5           | 0             | 0            |
| Romance forever      | 5             | ?           | ?             | 0            |
| Cute puppies of love | ?             | 4           | 0             | ?            |
| Nonstop car chases   | 0             | 0           | 5             | 4            |
| Swords vs. karate    | 0             | 0           | 5             | ?            |

![](../images/42a92e07b32b593bb826f8f6bc4d9eb3.png)

推出评分：

![](../images/c905a6f02e201a4767d869b3791e8aeb.png)

上述矩阵是用户特征矩阵 $\Theta$ 与电影特征矩阵 $X$ 的乘积：
$$
X\Theta^{T}=\begin{bmatrix}...x^{(1)}...\\...x^{(2)}...\\...\\...\\...x^{(n_m)}\end{bmatrix}\begin{bmatrix}...\theta^{(1)}...\\...\theta^{(2)}...\\...\\...\\...\theta^{(n_u)}...\end{bmatrix}^T
$$


找到相关影片：

![](../images/0a8b49da1ab852f2996a02afcaca2322.png)

==低秩矩阵表明该矩阵中有很多线性相关的重复行向量或列向量，我们以此为出发点，找到矩阵内与？处线性相关的向量，即可预测？处合理的数据。==

**For each product $i$ , we learn a feature vector $x^{(i)}\in{\R^{n}}$:**

对于某件商品 $i$ ，比如电影 $i$ ，我们已经学习到一个属性向量 $x^{(i)}$ ，当你学习某组特征时，你之前并不知道该选取哪些不同的特征，但是如果你运行这个算法，将捕捉到有关电影和商品的重要的信息，这些信息将导致一些用户喜欢某些电影，另外一些用户喜欢另外一些电影。可能你最终学习到一个特征向量，或许 $x_1$ 代表浪漫爱情，$x_2$ 代表动作片，也许 $x_3$ 代表喜剧效果，$x_4$ 代表其他含义等等，这样你总共有 $N$ 个特征。在你学习完特征之后，实际上很难理解这些被学习到的特征，并对特征给出人类可以理解的解释。但是实际上，即使这些特征难以可视化，人们难以理解这些特征的含义，但通常，算法将学到一些有意义的特征，它们捕捉到一部电影最重要的特征，这些特征导致了你喜欢或不喜欢这部电影。

**How to find movie $j$ related to movie $i$ ?**

现在，比如你有一部电影 $i$ ，你想找到另一部电影 $j$ ，它与电影 $i$ 相关，为什么你要这样做呢。假设你有一个用户，他正在观看电影 $j$ ，那么在他观看完后，再推荐给他观看哪一部电影比较合理呢？现在既然你已经学习到了这些特征向量，它给我们一种方便的方法去衡量两个电影的相似度，即 $\parallel{x}^{(i)}-{x}^{(j)}\parallel$ 之间的距离越小，表示电影 $i$ 与电影 $j$ 越相似。至少在感觉上，喜欢电影 $i$ 的人，也可能喜欢电影 $j$ 。

**5 most similar movies to movie $i$ :**

简要回顾一下，如果你的用户正在观看电影 $i$ ，如果你想找到5部与电影 $i$ 最相似的电影，目的是推荐给你的用户，你要做的是找到五部电影 $j$ ，这些电影的特征向量与电影 $i$ 的特征向量有最小的距离，这样你就能向你的用户推荐几部不同的电影了。

通过以上的学习，希望你能知道，如何使用一个向量化手段来计算所有用户对所有电影的评分预测值，也可以实现利用已经学习到的特征，来找到彼此相类似的电影或商品。

### 16.6 推行工作上的细节：均值归一化

参考视频: 16 - 6 - Implementational Detail\_ Mean Normalization (9 min).mkv

让我们来看下面的用户评分数据：

![](../images/54b1f7c3131aed24f9834d62a6835642.png)

如果我们新增一个用户 **Eve**，并且 **Eve** 没有为任何电影评分，那么我们以什么为依据为**Eve**推荐电影呢？
$$
J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2
$$

				1. 假设特征数 $n=2$ ，所以我们要学习5号用户**Eve**两个特征变量 $\theta^{(5)}\in{\R^2}$，
   				2. 代价函数中，由于**Eve**没有对任何电影评分，所以他没有对应的 $r(i,j)=1$，所以第一项不产生影响，第二项 $x_{k}^{(j)}$ 也没有影响，最后一项成为唯一要优化的项。

3. 为了最小化代价函数，$J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)})=\frac{\lambda}{2}\begin{bmatrix}(\theta_1^{(5)})^2+(\theta_2^{(5)})^2\end{bmatrix}$ ，所以最终的 $\theta^{(5)}=\begin{bmatrix}0\\0\end{bmatrix}$ ，所以我们预测用户5会给所有电影打0分，因为对于任意的电影 $i$ ，都有 $(\theta^{(5)})^Tx^{(i)}=0$ 

均值归一化的思想，能让我们解决这个问题：

1. 我们首先需要对结果 $Y $矩阵进行均值归一化处理，对每一行求均值（每行代表该电影的平均得分），然后用每个用户对该电影的评分减去该电影平均分，处理后，每部电影在新矩阵中的平均评分都是0：

![](../images/9ec5cb55e14bd1462183e104f8e02b80.png)

2. 然后我们利用这个新的 $Y$ 矩阵运行协同过滤算法：

   ​			新的预测评分为： $(\theta^{(i)})^T(x^{(i)})+\mu_i$ ，$\mu_i$ 为每部电影的原始平均评分

3. 对于用户5（**Eve**）：

   ​			和之前一样，由于**Eve**没有给任何电影打分，所以学习到的结果仍然是 $\theta^{(5)}=\begin{bmatrix}0\\0\end{bmatrix}$ 。对于特定的电影 $i$ ：$(\theta^{(i)})^T(x^{(i)})+\mu_i=\mu_i$。

   ​			这实际上是有意义的，对于没有给任何电影评分的用户，我们预测他为平均分。

在本案例中，我们归一化了矩阵的每一行，如果某部电影没有任何评分，你也可以尝试归一化每一列。但这可能不太重要，因为如果某部电影没有任何评分，你就不该把这部电影推荐给任何用户。所以，关注没有进行过任何评分的用户比关注没被评价过的电影更重要一些。

最后总结一下：以上就是均值归一化的实现过程，它作为协同过滤算法的预处理步骤，根据不同的数据集，它有时能让你的算法表现的更好一些。