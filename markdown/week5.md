第5周
=====
[TOC]

九、神经网络的学习(Neural Networks: Learning)
---------------------------------------------

### 9.1 代价函数

参考视频: 9 - 1 - Cost Function (7 min).mkv

首先引入一些便于稍后讨论的新标记方法：

假设神经网络的训练样本有$m$个，每个包含一组输入$x$和一组输出信号$y$，$L$表示神经网络层数，$S_I$表示每层的**neuron**个数($S_l$表示输出层神经元个数)，$S_L$代表最后一层中处理单元的个数。

将神经网络的分类定义为两种情况：二类分类和多类分类，

二类分类：$S_L=0, y=0\, or\, 1$表示哪一类；

$K$类分类：$S_L=k, y_i = 1$表示分到第$i$类；$(k>2)$

![](../images/8f7c28297fc9ed297f42942018441850.jpg)

我们回顾逻辑回归问题中我们的代价函数为：

$  J\left(\theta \right)=-\frac{1}{m}\left[\sum_\limits{i=1}^{m}{y}^{(i)}\log{h_\theta({x}^{(i)})}+\left(1-{y}^{(i)}\right)log\left(1-h_\theta\left({x}^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_\limits{j=1}^{n}{\theta_j}^{2}  $

在逻辑回归中，我们只有一个输出变量，又称标量（**scalar**），也只有一个因变量$y$，但是在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些，为：$\newcommand{\subk}[1]{ #1_k }$
$$h_\theta\left(x\right)\in \mathbb{R}^{K}$$ $${\left({h_\theta}\left(x\right)\right)}_{i}={i}^{th} \text{output}$$

$J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_{l+1}} \left( \Theta_{ji}^{(l)} \right)^2$

这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出$K​$个预测，基本上我们可以利用循环，对每一行特征都预测$K​$个不同结果，然后在利用循环在$K​$个预测中选择可能性最高的一个，将其与$y​$中的实际数据进行比较。

正则化的那一项只是排除了每一层$\theta_0$后，每一层的$\theta$ 矩阵的和。最里层的循环$j$循环所有的行（由$s_{l+1}$  层的激活单元数决定），循环$i$则循环所有的列，由该层（$s_l$层）的激活单元数所决定。即：$h_\theta(x)$与真实值之间的距离为每个样本-每个类输出的加和，对参数进行**regularization**的**bias**项处理所有参数的平方和。

### 9.2 反向传播算法

参考视频: 9 - 2 - Backpropagation Algorithm (12 min).mkv

之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的$h_{\theta}\left(x\right)$。

现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij}}J\left(\Theta\right)$，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。
以一个例子来说明反向传播算法。

假设我们的训练集只有一个样本$\left({x}^{(1)},{y}^{(1)}\right)$，我们的神经网络是一个四层的神经网络，其中$K=4，S_{L}=4，L=4$：

前向传播算法：

![](../images/2ea8f5ce4c3df931ee49cf8d987ef25d.png)

下面的公式推导过程见：<https://blog.csdn.net/qq_29762941/article/details/80343185>

我们从最后一层的误差开始计算，误差是激活单元的预测（${a^{(4)}}​$）与实际值（$y^k​$）之间的误差，（$k=1:k​$）。
我们用$\delta​$来表示误差，则：$\delta^{(4)}=a^{(4)}-y​$
我们利用这个误差值来计算前一层的误差：$\delta^{(3)}=\left({\Theta^{(3)}}\right)^{T}\delta^{(4)}\ast g'\left(z^{(3)}\right)​$
其中 $g'(z^{(3)})​$是 $S​$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})​$。而$(θ^{(3)})^{T}\delta^{(4)}​$则是权重导致的误差的和。下一步是继续计算第二层的误差：
$ \delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}\ast g'(z^{(2)})​$
因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0​$，即我们不做任何正则化处理时有：
$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}​$

重要的是清楚地知道上面式子中上下标的含义：

$l$ 代表目前所计算的是第几层。

$j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标。

$i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。

如果我们考虑正则化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用$\Delta^{(l)}_{ij}$来表示这个误差矩阵。第 $l$  层的第 $i$ 个激活单元受到第 $j$ 个参数影响而导致的误差。

我们的算法表示为：

![](../images/5514df14ebd508fd597e552fbadcf053.jpg)

即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。

在求出了$\Delta_{ij}^{(l)}​$之后，我们便可以计算代价函数的偏导数了，计算方法如下：
$ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}​$              ${if}\; j \neq  0​$

$ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}​$                             ${if}\; j = 0​$

在**Octave** 中，如果我们要使用 `fminuc`这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。

假设我们有三个权重矩阵，Theta1，Theta2 和 Theta3，尺寸分别为 10\*11，10\*11 和1*11，
下面的代码可以实现这样的转换：

```
thetaVec = [Theta1(:) ; Theta2(:) ; Theta3(:)]

...optimization using functions like fminuc...

Theta1 = reshape(thetaVec(1:110, 10, 11);

Theta2 = reshape(thetaVec(111:220, 10, 11);

Theta1 = reshape(thetaVec(221:231, 1, 11);
```



### 9.3 反向传播算法的直观理解

参考视频: 9 - 3 - Backpropagation Intuition (13 min).mkv

反向传播是计算代价函数关于所有参数的导数或偏导数的一种有效方法。

在上一段视频中，我们介绍了反向传播算法，对很多人来说，当第一次看到这种算法时，第一印象通常是，这个算法需要那么多繁杂的步骤，简直是太复杂了，实在不知道这些步骤，到底应该如何合在一起使用。就好像一个黑箱，里面充满了复杂的步骤。如果你对反向传播算法也有这种感受的话，这其实是正常的，相比于线性回归算法和逻辑回归算法而言，从数学的角度上讲，反向传播算法似乎并不简洁，对于反向传播这种算法，其实我已经使用了很多年了，但即便如此，即使是现在，我也经常感觉自己对反向传播算法的理解并不是十分深入，对于反向传播算法究竟是如何执行的，并没有一个很直观的理解。做过编程练习的同学应该可以感受到这些练习或多或少能帮助你，将这些复杂的步骤梳理了一遍，巩固了反向传播算法具体是如何实现的，这样你才能自己掌握这种算法。

在这段视频中，我想更加深入地讨论一下反向传播算法的这些复杂的步骤，并且希望给你一个更加全面直观的感受，理解这些步骤究竟是在做什么，也希望通过这段视频，你能理解，它至少还是一个合理的算法。但可能你即使看了这段视频，你还是觉得反向传播依然很复杂，依然像一个黑箱，太多复杂的步骤，依然感到有点神奇，这也是没关系的。即使是我接触反向传播这么多年了，有时候仍然觉得这是一个难以理解的算法，但还是希望这段视频能有些许帮助，为了更好地理解反向传播算法，我们再来仔细研究一下前向传播的原理：

前向传播算法：

![](../images/5778e97c411b23487881a87cfca781bb.png)

![](../images/63a0e4aef6d47ba7fa6e07088b61ae68.png)

反向传播算法做的是：

![](../images/57aabbf26290e2082a00c5114ae1c5dc.png)

![](../images/1542307ad9033e39093e7f28d0c7146c.png)

**感悟**：上图中的 $\delta^{(l)}_{j}="error" \ of cost \  for \ a^{(l)}_{j} \ (unit \ j \ in \ layer \ l)​$ 理解如下：

$\delta^{(l)}_{j}$ 相当于是第 $l$ 层的第 $j$ 单元中得到的激活项的“误差”，即”正确“的 $a^{(l)}_{j}$ 与计算得到的 $a^{(l)}_{j}$ 的差。

而 $a^{(l)}_{j}=g(z^{(l)})​$ ，（g为sigmoid函数）。我们可以想象 $\delta^{(l)}_{j}​$ 为函数求导时迈出的那一丁点微分，所以更准确的说 $\delta^{(l)}_{j}=\frac{\partial}{\partial z^{(l)}_{j}}cost(i)​$

### 9.4 实现注意：展开参数

参考视频: 9 - 4 - Implementation Note\_ Unrolling Parameters (8 min).mkv

在上一段视频中，我们谈到了怎样使用反向传播算法计算代价函数的导数。在这段视频中，我想快速地向你介绍一个细节的实现过程，怎样把你的参数从矩阵展开成向量，以便我们在高级最优化步骤中的使用需要。

![](../images/0ad78547859e6f794a7f18389d3d6128.png)

具体来讲，当你执行了代价函数 $function \ [jVal, \ gradient]=costFunction(theta)$ 输入参数是$theta$，函数返回代价值以及导数值。

然后你可以将返回值传递给高级最优化算法$optTheta=fminunc(@costFunction, \ initialTheta, \ options)​$ ，$fminunc​$并不是唯一算法，你也可以使用别的优化算法，但他们的功能都是取出这些输入值( $@costFunction​$ 以及$theta​$ 值的一些初始值)，并且这些程序都假定 $theta​$ 和这些 $theta​$ 初始值都是参数向量，也许是 $n​$ 或 ${n+1}​$ 维，但他们都是向量，同时假定这个代价函数 $function​$ 的第二个返回值，也就是梯度值 $gradient​$ 也是 $n​$ 维或 ${n+1}​$ 维，所以它也是一个向量。

这部分在我们使用逻辑回归时没问题，但现在我们用神经网络，我们的参数不再是向量了，而是 $\Theta^{(1)},\Theta^{(2)},\Theta^{(3)}$ 矩阵了，因此对于一个完整的神经网络，我们在Octave中可以设为矩阵 $Theta1,\ Theta2 \ Theta3$ ，同样这些梯度项也是需要得到的返回值。

$\Theta^{(1)}, \Theta^{(2)}, \Theta^{(3)}:matrices(Theta1, \ Theta2, \ Theta3)$

$D^{(1)}, D^{(1)}, D^{(1)}:matrices(D1, \ D2, \ D3)$

那么在之前的视频中，我们演示了如何计算这些梯度矩阵 $D1, \ D2, \ D3$，在这节视频中我想很快的向你介绍，怎样取出这些矩阵，并且将它们展开成向量，以便它们最终成为恰当的格式，能够传入到 $costFunction(theta)$ 中的 $theta$ ，并且得到梯度返回值。

具体来说，假设我们有下图这样一个神经网络，其输入层和隐藏层都有10个单元，最后的输出层只有1个输出单元，所以 单元数s， 矩阵$\Theta$，矩阵$D$ 的维度如下图那样。

![](../images/f9284204de41bffa4f7bc1dea567044e.png)

在Octave中如果你想在矩阵和向量之间来回转换，可以通过如下代码取出三个 $\Theta​$ 矩阵中的所有元素，即将 $Theta1​$ , $Theta2​$ , $Theta3​$ 全部展开成为一个很长的向量，也就是 $thetaVec​$ ，同样的也可以得到 $Dvec​$ 。

![](../images/ffafklzv446v1123fj4fa131ckad8.png)

如果你想从向量表达式返回矩阵表达式的话，可以用如下代码。例如取 $thetaVec$ 的前110个元素，将其reshape成 $10\times11$ 维就能得到 $Theta1$

![](../images/dac14dfa5ad6h1yeu1m5ddg5h6kk84r.png)

为了使上面的过程更具体，下面我们看怎样将上面的方法应用于我们的学习算法：

![](../images/ebd7e196e272737f497853ba60743c44.png)

总结：

矩阵表达式的好处：当你在前向传播和反向传播时，矩阵形式会非常方便，更容易充分利用向量化实现。

向量表达式的好处：若你有 $thetaVec$ 或 $DVec$ 这样的矩阵，当你使用一些高级优化算法时，这些算法通常要求传入的参数为向量形式。

希望通过本节课程，你能在两种形式之间轻松的转换。

### 9.5 梯度检验

参考视频: 9 - 5 - Gradient Checking (12 min).mkv

当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时（或使用其他算法时），可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。

为了避免这样的问题，我们采取一种叫做梯度的数值检验（**Numerical Gradient Checking**）方法。它能解决几乎所有这种问题，现在我每次在神经网络或其他复杂模型中实现反向传播或者类似梯度下降算法时，都会做梯度检验。它会保证你的前向传播和后向传播100%正确。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。

对梯度的估计采用的方法是在代价函数上选择两个非常近的点，用这两点连线的斜率去代替两点中点的导数。即对于某个特定的 $\theta​$，我们计算出在 $\theta​$-$\varepsilon ​$ 处和 $\theta​$+$\varepsilon ​$ 两点处的代价值 $J(\theta)​$（其中 $\varepsilon ​$是一个非常小的值，通常选取 0.0001量级的），然后求两点连线的的斜率，用以估计在 $\theta​$ 处的导数值。

如下图，当 $\varepsilon$ 非常小时，$\frac{\partial}{\partial(\theta)}J(\theta) \approx \frac{J(\theta + \varepsilon)-J(\theta - \varepsilon)}{2 \varepsilon}$ ，即 红线斜率 $\approx$ 绿线斜率

当 $\varepsilon​$ 无限趋近于0时，上式可以画等号。

![](../images/5d04c4791eb12a74c843eb5acf601400.png)



**Octave** 中代码如下：

`gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps)`

上面是 $\theta​$ 为一个实数时的情况，更普遍地当$\theta​$是一个向量时，我们可以类似地对所以偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对$\theta_1​$进行检验的示例：
$$ \frac{\partial}{\partial\theta_1} \approx \frac{J\left(\theta_1+\varepsilon,\theta_2,\theta_3,...,\theta_n \right)-J \left( \theta_1-\varepsilon,\theta_2,\theta_3,...,\theta_n \right)}{2\varepsilon} ​$$

$ \frac{\partial}{\partial\theta_2} \approx \frac{J\left(\theta_1,\theta_2+\varepsilon,\theta_3,...,\theta_n \right)-J \left( \theta_1,\theta_2 - \varepsilon,\theta_3,...,\theta_n \right)}{2\varepsilon} ​$

...

$ \frac{\partial}{\partial\theta_n} \approx \frac{J\left(\theta_1,\theta_2,\theta_3,...,\theta_n + \varepsilon \right)-J \left( \theta_1,\theta_2,\theta_3,...,\theta_n - \varepsilon \right)}{2\varepsilon} ​$

最后我们还需要对通过反向传播方法计算出的偏导数进行检验。

根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。

```python
										theta = np.array()       # theta为array对象
    
    									for i in range(1, n+1):
        									thetaPlus = theta + epsilon
                							thetaMins = theta - epsilon
                    						
                        					gradApprox = ( J(thetaPlus[i]) - J(thetaMins[i]) ) / (2*epsilon)  # 代价函数J另外实现
                            
                            			Check that gradApprox ≈ DVec   # 比较计算得到的偏导数和反向传播中得到的梯度
```

反向传播是计算代价函数关于所有参数的导数或偏导数的一种有效方法，我们通常要做的是验证这个计算出的导数 gradApprox 是否在数值上等于 反向传播计算出的导数 DVec，如果这两种方法计算出的导数是一样的，或者说非常接近（只有几位小数的差距），那么我就可以确信反向传播的实现是正确的，并且能很好的优化 $J(\Theta)​$ 。

最后，总结下整个过程，掌握如何实现数值上的梯度检验：

![](../images/bf65f3f3098025530a3c442eea562f8c.png)

### 9.6 随机初始化

参考视频: 9 - 6 - Random Initialization (7 min).mkv

任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。

![](../images/bf65ddg3f3098025530a3c442eeafadf62f8c.png)

我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下：

```octave
Theta1 = rand(10, 11) * (2*eps) – eps     # 10 × 11维的(0,1)之间的数，然后再乘2倍的eps，最后再减去eps。
```

梯度检验中的 $\varepsilon$ 与上述代码中的 $\varepsilon$ 没什么关联。

总结：

1. 为了训练神经网络，首先将权重 $\theta​$ 随机初始化为一个范围在 $(-\varepsilon,+\varepsilon)​$ 之间的数。
2. 然后进行反向传播。
3. 再进行梯度检验。
4. 最后使用梯度下降或其他高级优化算法，来最小化代价函数 $J(\Theta)$ ，找到最优化的 $\Theta$。

### 9.7 综合起来

参考视频: 9 - 7 - Putting It Together (14 min).mkv

小结一下使用神经网络时的步骤：

1. 网络架构：选择网络架构(神经元之间的连接模式)，即决定选择多少层以及决定每层分别有多少个单元。

   1. 输入层：输入层的单元数即我们训练集的特征数量。

   2. 输出层：输出层的单元数是所要区分的类别个数（记得把 label 写成向量的形式，见本节末尾）。

   3. 隐藏层：1. 通常我们使用最多的架构就是只有一个隐藏层。

      ​		2. 如果选取隐藏层数大于1，确保每个隐藏层的单元个数相同。

      ​		3. 通常情况下隐藏层单元的个数越多越好（但计算量会很大）。但隐藏层单元数目最好是特征数目的整数倍。

      如果你遵循这些选取网络架构的建议，通常会得到比较好的模型结构。（后续的课程中，我还会着重讲解如何选取神经网络结构）

2. 训练神经网络：

   1. 参数的随机初始化（很小接近于0，在$(-\varepsilon,+\varepsilon)$之间）

   2. 利用正向传播方法计算所有的$h_{\theta}(x)​$

   3. 计算代价函数 $J(\Theta)$ 

   4. 执行反向传播方法计算所有偏导数 $\frac{\partial}{\partial\Theta^{(l)}_{jk}}J(\Theta)$

   5. 利用梯度检验比较 “反向传播算法得到的偏导数项” 与 “数值方法得到的偏导数项”。

   6. 使用优化算法（梯度下降或高级优化法如共轭梯度法）来最小化代价函数 $J(\Theta)$ 

      备注：$J(\Theta)$ 是一个非凸函数，梯度下降法及其他优化算法都有可能停留在局部极值点，但实际工作中这一般不是大问题，通常都表现不错。

**关于1.2中 label 写成向量的形式：**

​	假设有4中不同的 label，则 : 
$$
y_1= \left[\begin{matrix}
			 1\\
             0\\
             0\\
             0
             \end{matrix}\right],
y_2= \left[\begin{matrix}
			 0\\
             1\\
             0\\
             0
             \end{matrix}\right],
y_3= \left[\begin{matrix}
			 0\\
             0\\
             1\\
             0
             \end{matrix}\right],
y_4= \left[\begin{matrix}
			 0\\
             0\\
             0\\
             1
             \end{matrix}\right]
$$
**关于2.4反向传播算法，有比较先进的向量化方法，但第一次执行反向传播，我还是建议你用 for 循环来对m个样本遍历，对每一个样本进行迭代：**

1. $(x^{(1)},y^{(1)})​$ ：先 正向传播，再 反向传播。
2. $(x^{(2)},y^{(2)})​$ ：先 正向传播，再 反向传播。
3. ......
4. $(x^{(m)},y^{(m)})$ ：先 正向传播，再 反向传播。

**关于反向传播和梯度下降在神经网络中的基本原理直观理解：**

![](../images/ade43dc51da181d3dwe681cd7d6ceaf4f2e46.png)

### 9.8 自主驾驶

参考视频: 9 - 8 - Autonomous Driving (7 min).mkv

在这段视频中，我想向你介绍一个具有历史意义的神经网络学习的重要例子。那就是使用神经网络来实现自动驾驶，也就是说使汽车通过学习来自己驾驶。接下来我将演示的这段视频是我从 Dean Pomerleau那里拿到的，他是我的同事，任职于美国东海岸的卡耐基梅隆大学。在这部分视频中，你就会明白可视化技术到底是什么？在看这段视频之前，我会告诉你可视化技术是什么。

在下面也就是左下方，就是汽车所看到的前方的路况图像。

![](../images/cea3f9a181d326681cd7d6ceaf4f2e46.png)

在图中你依稀能看出一条道路，朝左延伸了一点，又向右了一点，然后上面的这幅图，你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向。就是这里的这条白亮的区段显示的就是人类驾驶者选择的方向。比如：最左边的区段，对应的操作就是向左急转，而最右端则对应向右急转的操作。因此，稍微靠左的区段，也就是中心稍微向左一点的位置，则表示在这一点上人类驾驶者的操作是慢慢的向左拐。

这幅图的第二部分对应的就是学习算法选出的行驶方向。并且，类似的，这一条白亮的区段显示的就是神经网络在这里选择的行驶方向，是稍微的左转，并且实际上在神经网络开始学习之前，你会看到网络的输出是一条灰色的区段，就像这样的一条灰色区段覆盖着整个区域这些均称的灰色区域，显示出神经网络已经随机初始化了，并且初始化时，我们并不知道汽车如何行驶，或者说我们并不知道所选行驶方向。只有在学习算法运行了足够长的时间之后，才会有这条白色的区段出现在整条灰色区域之中。显示出一个具体的行驶方向这就表示神经网络算法，在这时候已经选出了一个明确的行驶方向，不像刚开始的时候，输出一段模糊的浅灰色区域，而是输出一条白亮的区段，表示已经选出了明确的行驶方向。

![](../images/56441d35d8bd4ecfd6d6f32b651c54a6.png)

**ALVINN** (**Autonomous Land Vehicle In a Neural Network**)是一个基于神经网络的智能系统，通过观察人类的驾驶来学习驾驶，**ALVINN**能够控制**NavLab**，装在一辆改装版军用悍马，这辆悍马装载了传感器、计算机和驱动器用来进行自动驾驶的导航试验。实现**ALVINN**功能的第一步，是对它进行训练，也就是训练一个人驾驶汽车。

![](../images/41cdc4cd2bc49a1b75d57aaf748e0798.png)

然后让**ALVINN**观看，**ALVINN**每两秒将前方的路况图生成一张数字化图片，并且记录驾驶者的驾驶方向，得到的训练集图片被压缩为30x32像素，并且作为输入提供给**ALVINN**的三层神经网络，通过使用反向传播学习算法，**ALVINN**会训练得到一个与人类驾驶员操纵方向基本相近的结果。一开始，我们的网络选择出的方向是随机的，大约经过两分钟的训练后，我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向，对其他道路类型，也重复进行这个训练过程，当网络被训练完成后，操作者就可按下运行按钮，车辆便开始行驶了。

![](../images/dd4a022b5544d50f503c077b3a5a5251.png)

每秒钟**ALVINN**生成12次数字化图片，并且将图像传送给神经网络进行训练，多个神经网络同时工作，每一个网络都生成一个行驶方向，以及一个预测自信度的参数，预测自信度最高的那个神经网络得到的行驶方向。比如这里，在这条单行道上训练出的网络将被最终用于控制车辆方向，车辆前方突然出现了一个交叉十字路口，当车辆到达这个十字路口时，我们单行道网络对应的自信度骤减，当它穿过这个十字路口时，前方的双车道将进入其视线，双车道网络的自信度便开始上升，当它的自信度上升时，双车道的网络，将被选择来控制行驶方向，车辆将被安全地引导进入双车道路。

这就是基于神经网络的自动驾驶技术。当然，我们还有很多更加先进的试验来实现自动驾驶技术。在美国，欧洲等一些国家和地区，他们提供了一些比这个方法更加稳定的驾驶控制技术。但我认为，使用这样一个简单的基于反向传播的神经网络，训练出如此强大的自动驾驶汽车，的确是一次令人惊讶的成就。